{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KTlZzR9WpT1"
      },
      "source": [
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "def sigmoid(x): \n",
        "    return 1. / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(values): \n",
        "    return values*(1-values)\n",
        "\n",
        "def tanh_derivative(values): \n",
        "    return 1. - values ** 2\n",
        "\n",
        "# createst uniform random array w/ values in [a,b) and shape args\n",
        "def rand_arr(a, b, *args): \n",
        "    np.random.seed(0)\n",
        "    return np.random.rand(*args) * (b - a) + a\n",
        "\n",
        "class LstmParam:\n",
        "    def __init__(self, mem_cell_ct, x_dim):\n",
        "        self.mem_cell_ct = mem_cell_ct\n",
        "        self.x_dim = x_dim\n",
        "        concat_len = x_dim + mem_cell_ct\n",
        "        # weight matrices\n",
        "        self.wg = rand_arr(-0.1, 0.1, mem_cell_ct, concat_len)\n",
        "        self.wi = rand_arr(-0.1, 0.1, mem_cell_ct, concat_len) \n",
        "        self.wf = rand_arr(-0.1, 0.1, mem_cell_ct, concat_len)\n",
        "        self.wo = rand_arr(-0.1, 0.1, mem_cell_ct, concat_len)\n",
        "        # bias terms\n",
        "        self.bg = rand_arr(-0.1, 0.1, mem_cell_ct) \n",
        "        self.bi = rand_arr(-0.1, 0.1, mem_cell_ct) \n",
        "        self.bf = rand_arr(-0.1, 0.1, mem_cell_ct) \n",
        "        self.bo = rand_arr(-0.1, 0.1, mem_cell_ct) \n",
        "        # diffs (derivative of loss function w.r.t. all parameters)\n",
        "        self.wg_diff = np.zeros((mem_cell_ct, concat_len)) \n",
        "        self.wi_diff = np.zeros((mem_cell_ct, concat_len)) \n",
        "        self.wf_diff = np.zeros((mem_cell_ct, concat_len)) \n",
        "        self.wo_diff = np.zeros((mem_cell_ct, concat_len)) \n",
        "        self.bg_diff = np.zeros(mem_cell_ct) \n",
        "        self.bi_diff = np.zeros(mem_cell_ct) \n",
        "        self.bf_diff = np.zeros(mem_cell_ct) \n",
        "        self.bo_diff = np.zeros(mem_cell_ct) \n",
        "\n",
        "    def apply_diff(self, lr = 1):\n",
        "        self.wg -= lr * self.wg_diff\n",
        "        self.wi -= lr * self.wi_diff\n",
        "        self.wf -= lr * self.wf_diff\n",
        "        self.wo -= lr * self.wo_diff\n",
        "        self.bg -= lr * self.bg_diff\n",
        "        self.bi -= lr * self.bi_diff\n",
        "        self.bf -= lr * self.bf_diff\n",
        "        self.bo -= lr * self.bo_diff\n",
        "        # reset diffs to zero\n",
        "        self.wg_diff = np.zeros_like(self.wg)\n",
        "        self.wi_diff = np.zeros_like(self.wi) \n",
        "        self.wf_diff = np.zeros_like(self.wf) \n",
        "        self.wo_diff = np.zeros_like(self.wo) \n",
        "        self.bg_diff = np.zeros_like(self.bg)\n",
        "        self.bi_diff = np.zeros_like(self.bi) \n",
        "        self.bf_diff = np.zeros_like(self.bf) \n",
        "        self.bo_diff = np.zeros_like(self.bo) \n",
        "\n",
        "class LstmState:\n",
        "    def __init__(self, mem_cell_ct, x_dim):\n",
        "        self.g = np.zeros(mem_cell_ct)\n",
        "        self.i = np.zeros(mem_cell_ct)\n",
        "        self.f = np.zeros(mem_cell_ct)\n",
        "        self.o = np.zeros(mem_cell_ct)\n",
        "        self.s = np.zeros(mem_cell_ct)\n",
        "        self.h = np.zeros(mem_cell_ct)\n",
        "        self.bottom_diff_h = np.zeros_like(self.h)\n",
        "        self.bottom_diff_s = np.zeros_like(self.s)\n",
        "    \n",
        "class LstmNode:\n",
        "    def __init__(self, lstm_param, lstm_state):\n",
        "        # store reference to parameters and to activations\n",
        "        self.state = lstm_state\n",
        "        self.param = lstm_param\n",
        "        # non-recurrent input concatenated with recurrent input\n",
        "        self.xc = None\n",
        "\n",
        "    def bottom_data_is(self, x, s_prev = None, h_prev = None):\n",
        "        print(x.shape)\n",
        "        # if this is the first lstm node in the network\n",
        "        if s_prev is None: s_prev = np.zeros_like(self.state.s)\n",
        "        if h_prev is None: h_prev = np.zeros_like(self.state.h)\n",
        "        # save data for use in backprop\n",
        "        self.s_prev = s_prev\n",
        "        self.h_prev = h_prev\n",
        "\n",
        "        # concatenate x(t) and h(t-1)\n",
        "        xc = np.hstack((x,  h_prev))\n",
        "        self.state.g = np.tanh(np.dot(self.param.wg, xc) + self.param.bg)\n",
        "        self.state.i = sigmoid(np.dot(self.param.wi, xc) + self.param.bi)\n",
        "        self.state.f = sigmoid(np.dot(self.param.wf, xc) + self.param.bf)\n",
        "        self.state.o = sigmoid(np.dot(self.param.wo, xc) + self.param.bo)\n",
        "        self.state.s = self.state.g * self.state.i + s_prev * self.state.f\n",
        "        ##self.state.h = self.state.s * self.state.o\n",
        "        self.state.h = np.tanh(self.state.s) * self.state.o\n",
        "\n",
        "        self.xc = xc\n",
        "    \n",
        "    def top_diff_is(self, top_diff_h, top_diff_s):\n",
        "        # notice that top_diff_s is carried along the constant error carousel\n",
        "        ds = self.state.o * top_diff_h + top_diff_s\n",
        "        do = self.state.s * top_diff_h\n",
        "        di = self.state.g * ds\n",
        "        dg = self.state.i * ds\n",
        "        df = self.s_prev * ds\n",
        "\n",
        "        # diffs w.r.t. vector inside sigma / tanh function\n",
        "        di_input = sigmoid_derivative(self.state.i) * di \n",
        "        df_input = sigmoid_derivative(self.state.f) * df \n",
        "        do_input = sigmoid_derivative(self.state.o) * do \n",
        "        dg_input = tanh_derivative(self.state.g) * dg\n",
        "\n",
        "        # diffs w.r.t. inputs\n",
        "        self.param.wi_diff += np.outer(di_input, self.xc)\n",
        "        self.param.wf_diff += np.outer(df_input, self.xc)\n",
        "        self.param.wo_diff += np.outer(do_input, self.xc)\n",
        "        self.param.wg_diff += np.outer(dg_input, self.xc)\n",
        "        self.param.bi_diff += di_input\n",
        "        self.param.bf_diff += df_input       \n",
        "        self.param.bo_diff += do_input\n",
        "        self.param.bg_diff += dg_input       \n",
        "\n",
        "        # compute bottom diff\n",
        "        dxc = np.zeros_like(self.xc)\n",
        "        dxc += np.dot(self.param.wi.T, di_input)\n",
        "        dxc += np.dot(self.param.wf.T, df_input)\n",
        "        dxc += np.dot(self.param.wo.T, do_input)\n",
        "        dxc += np.dot(self.param.wg.T, dg_input)\n",
        "\n",
        "        # save bottom diffs\n",
        "        self.state.bottom_diff_s = ds * self.state.f\n",
        "        self.state.bottom_diff_h = dxc[self.param.x_dim:]\n",
        "\n",
        "class LstmNetwork():\n",
        "    def __init__(self, lstm_param):\n",
        "        self.lstm_param = lstm_param\n",
        "        self.lstm_node_list = []\n",
        "        # input sequence\n",
        "        self.x_list = []\n",
        "\n",
        "    def y_list_is(self, y_list, loss_layer):\n",
        "        \"\"\"\n",
        "        Updates diffs by setting target sequence \n",
        "        with corresponding loss layer. \n",
        "        Will *NOT* update parameters.  To update parameters,\n",
        "        call self.lstm_param.apply_diff()\n",
        "        \"\"\"\n",
        "        assert len(y_list) == len(self.x_list)\n",
        "        idx = len(self.x_list) - 1\n",
        "        # first node only gets diffs from label ...\n",
        "        loss = loss_layer.loss(self.lstm_node_list[idx].state.h, y_list[idx])\n",
        "        diff_h = loss_layer.bottom_diff(self.lstm_node_list[idx].state.h, y_list[idx])\n",
        "        # here s is not affecting loss due to h(t+1), hence we set equal to zero\n",
        "        diff_s = np.zeros(self.lstm_param.mem_cell_ct)\n",
        "        self.lstm_node_list[idx].top_diff_is(diff_h, diff_s)\n",
        "        idx -= 1\n",
        "\n",
        "        ### ... following nodes also get diffs from next nodes, hence we add diffs to diff_h\n",
        "        ### we also propagate error along constant error carousel using diff_s\n",
        "        while idx >= 0:\n",
        "            loss += loss_layer.loss(self.lstm_node_list[idx].state.h, y_list[idx])\n",
        "            diff_h = loss_layer.bottom_diff(self.lstm_node_list[idx].state.h, y_list[idx])\n",
        "            diff_h += self.lstm_node_list[idx + 1].state.bottom_diff_h\n",
        "            diff_s = self.lstm_node_list[idx + 1].state.bottom_diff_s\n",
        "            self.lstm_node_list[idx].top_diff_is(diff_h, diff_s)\n",
        "            idx -= 1 \n",
        "\n",
        "        return loss\n",
        "\n",
        "    def x_list_clear(self):\n",
        "        self.x_list = []\n",
        "\n",
        "    def x_list_add(self, x):\n",
        "        self.x_list.append(x)\n",
        "        if len(self.x_list) > len(self.lstm_node_list):\n",
        "            # need to add new lstm node, create new state mem\n",
        "            lstm_state = LstmState(self.lstm_param.mem_cell_ct, self.lstm_param.x_dim)\n",
        "            self.lstm_node_list.append(LstmNode(self.lstm_param, lstm_state))\n",
        "\n",
        "        # get index of most recent x input\n",
        "        idx = len(self.x_list) - 1\n",
        "        if idx == 0:\n",
        "            # no recurrent inputs yet\n",
        "            self.lstm_node_list[idx].bottom_data_is(x)\n",
        "        else:\n",
        "            s_prev = self.lstm_node_list[idx - 1].state.s\n",
        "            h_prev = self.lstm_node_list[idx - 1].state.h\n",
        "            self.lstm_node_list[idx].bottom_data_is(x, s_prev, h_prev)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mh4G_11eWvsM",
        "outputId": "6fc69ed5-4ab1-44ec-f064-62e62b2bea55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "\n",
        "class ToyLossLayer:\n",
        "    \"\"\"\n",
        "    Computes square loss with first element of hidden layer array.\n",
        "    \"\"\"\n",
        "    @classmethod\n",
        "    def loss(self, pred, label):\n",
        "        return (pred[0] - label) ** 2\n",
        "\n",
        "    @classmethod\n",
        "    def bottom_diff(self, pred, label):\n",
        "        diff = np.zeros_like(pred)\n",
        "        diff[0] = 2 * (pred[0] - label)\n",
        "        return diff\n",
        "\n",
        "\n",
        "def example_0():\n",
        "    # learns to repeat simple sequence from random inputs\n",
        "    np.random.seed(0)\n",
        "\n",
        "    # parameters for input data dimension and lstm cell count\n",
        "    mem_cell_ct = 100\n",
        "    x_dim = 50\n",
        "    lstm_param = LstmParam(mem_cell_ct, x_dim)\n",
        "    lstm_net = LstmNetwork(lstm_param)\n",
        "    y_list = [-0.5, 0.2, 0.1, -0.5]\n",
        "    input_val_arr = [np.random.random(x_dim) for _ in y_list]\n",
        "    print(len(input_val_arr))\n",
        "    for cur_iter in range(100):\n",
        "        print(\"iter\", \"%2s\" % str(cur_iter), end=\": \")\n",
        "        for ind in range(len(y_list)):\n",
        "            lstm_net.x_list_add(input_val_arr[ind])\n",
        "\n",
        "        print(\"y_pred = [\" +\n",
        "              \", \".join([\"% 2.5f\" % lstm_net.lstm_node_list[ind].state.h[0] for ind in range(len(y_list))]) +\n",
        "              \"]\", end=\", \")\n",
        "\n",
        "        loss = lstm_net.y_list_is(y_list, ToyLossLayer)\n",
        "        print(\"loss:\", \"%.3e\" % loss)\n",
        "        lstm_param.apply_diff(lr=0.1)\n",
        "        lstm_net.x_list_clear()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    example_0()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "iter  0: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [ 0.04127,  0.06923,  0.11705,  0.16441], loss: 7.518e-01\n",
            "iter  1: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.20852, -0.28294, -0.33018, -0.35061], loss: 5.256e-01\n",
            "iter  2: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.15670, -0.19800, -0.23603, -0.25956], loss: 4.470e-01\n",
            "iter  3: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.14831, -0.17494, -0.21246, -0.24621], loss: 4.263e-01\n",
            "iter  4: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.14775, -0.16299, -0.20141, -0.24638], loss: 4.110e-01\n",
            "iter  5: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.15074, -0.15571, -0.19560, -0.25244], loss: 3.972e-01\n",
            "iter  6: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.15571, -0.15069, -0.19232, -0.26153], loss: 3.838e-01\n",
            "iter  7: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.16188, -0.14675, -0.19021, -0.27214], loss: 3.707e-01\n",
            "iter  8: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.16877, -0.14317, -0.18850, -0.28336], loss: 3.576e-01\n",
            "iter  9: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.17607, -0.13953, -0.18670, -0.29456], loss: 3.446e-01\n",
            "iter 10: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.18361, -0.13551, -0.18452, -0.30538], loss: 3.315e-01\n",
            "iter 11: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.19127, -0.13091, -0.18179, -0.31561], loss: 3.182e-01\n",
            "iter 12: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.19903, -0.12551, -0.17836, -0.32513], loss: 3.046e-01\n",
            "iter 13: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.20689, -0.11909, -0.17413, -0.33391], loss: 2.905e-01\n",
            "iter 14: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.21490, -0.11142, -0.16895, -0.34196], loss: 2.756e-01\n",
            "iter 15: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.22321, -0.10221, -0.16270, -0.34933], loss: 2.597e-01\n",
            "iter 16: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.23203, -0.09125, -0.15527, -0.35615], loss: 2.425e-01\n",
            "iter 17: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.24170, -0.07841, -0.14660, -0.36265], loss: 2.239e-01\n",
            "iter 18: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.25265, -0.06373, -0.13673, -0.36913], loss: 2.039e-01\n",
            "iter 19: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.26519, -0.04738, -0.12572, -0.37587], loss: 1.827e-01\n",
            "iter 20: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.27945, -0.02952, -0.11352, -0.38292], loss: 1.606e-01\n",
            "iter 21: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.29524, -0.01039, -0.10004, -0.39017], loss: 1.383e-01\n",
            "iter 22: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.31224,  0.00967, -0.08530, -0.39751], loss: 1.163e-01\n",
            "iter 23: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.32997,  0.03015, -0.06952, -0.40487], loss: 9.555e-02\n",
            "iter 24: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.34791,  0.05044, -0.05312, -0.41224], loss: 7.665e-02\n",
            "iter 25: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.36549,  0.06998, -0.03665, -0.41959], loss: 6.014e-02\n",
            "iter 26: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.38223,  0.08825, -0.02066, -0.42686], loss: 4.627e-02\n",
            "iter 27: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.39775,  0.10491, -0.00564, -0.43396], loss: 3.502e-02\n",
            "iter 28: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.41180,  0.11978,  0.00809, -0.44078], loss: 2.617e-02\n",
            "iter 29: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.42432,  0.13280,  0.02035, -0.44722], loss: 1.937e-02\n",
            "iter 30: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.43529,  0.14406,  0.03114, -0.45317], loss: 1.425e-02\n",
            "iter 31: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.44484,  0.15365,  0.04045, -0.45863], loss: 1.045e-02\n",
            "iter 32: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.45305,  0.16181,  0.04856, -0.46347], loss: 7.644e-03\n",
            "iter 33: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.46015,  0.16860,  0.05534, -0.46793], loss: 5.597e-03\n",
            "iter 34: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.46611,  0.17442,  0.06144, -0.47161], loss: 4.096e-03\n",
            "iter 35: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.47142,  0.17901,  0.06606, -0.47534], loss: 3.018e-03\n",
            "iter 36: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.47554,  0.18332,  0.07115, -0.47767], loss: 2.207e-03\n",
            "iter 37: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.47982,  0.18593,  0.07332, -0.48147], loss: 1.660e-03\n",
            "iter 38: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.48202,  0.18990,  0.07937, -0.48146], loss: 1.195e-03\n",
            "iter 39: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.48661,  0.18974,  0.07658, -0.48770], loss: 9.846e-04\n",
            "iter 40: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.48543,  0.19608,  0.08934, -0.48135], loss: 6.893e-04\n",
            "iter 41: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49390,  0.18900,  0.07150, -0.49789], loss: 9.750e-04\n",
            "iter 42: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.48322,  0.20611,  0.11026, -0.47059], loss: 1.289e-03\n",
            "iter 43: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.50694,  0.17625,  0.04052, -0.52381], loss: 4.717e-03\n",
            "iter 44: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.46403,  0.23133,  0.16873, -0.42356], loss: 1.284e-02\n",
            "iter 45: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.53687,  0.11940, -0.07892, -0.59301], loss: 4.852e-02\n",
            "iter 46: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.38843,  0.28532,  0.28974, -0.27651], loss: 1.057e-01\n",
            "iter 47: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.56989, -0.05848, -0.31324, -0.67401], loss: 2.727e-01\n",
            "iter 48: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.40436,  0.25537,  0.17921, -0.40089], loss: 2.831e-02\n",
            "iter 49: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49802,  0.18502, -0.02698, -0.54234], loss: 1.815e-02\n",
            "iter 50: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.46000,  0.22621,  0.09985, -0.47456], loss: 2.935e-03\n",
            "iter 51: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.47942,  0.21211,  0.06010, -0.50196], loss: 2.166e-03\n",
            "iter 52: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.47538,  0.21822,  0.08366, -0.49044], loss: 1.297e-03\n",
            "iter 53: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.48121,  0.21456,  0.07685, -0.49662], loss: 1.112e-03\n",
            "iter 54: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.48212,  0.21522,  0.08329, -0.49461], loss: 8.596e-04\n",
            "iter 55: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.48481,  0.21377,  0.08312, -0.49628], loss: 7.191e-04\n",
            "iter 56: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.48630,  0.21328,  0.08568, -0.49613], loss: 5.840e-04\n",
            "iter 57: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.48800,  0.21232,  0.08666, -0.49675], loss: 4.844e-04\n",
            "iter 58: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.48931,  0.21160,  0.08813, -0.49693], loss: 3.992e-04\n",
            "iter 59: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49055,  0.21080,  0.08915, -0.49725], loss: 3.312e-04\n",
            "iter 60: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49160,  0.21007,  0.09020, -0.49745], loss: 2.746e-04\n",
            "iter 61: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49255,  0.20935,  0.09106, -0.49766], loss: 2.284e-04\n",
            "iter 62: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49338,  0.20868,  0.09187, -0.49783], loss: 1.900e-04\n",
            "iter 63: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49412,  0.20804,  0.09258, -0.49798], loss: 1.584e-04\n",
            "iter 64: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49478,  0.20745,  0.09323, -0.49811], loss: 1.322e-04\n",
            "iter 65: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49536,  0.20688,  0.09381, -0.49823], loss: 1.104e-04\n",
            "iter 66: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49588,  0.20636,  0.09433, -0.49834], loss: 9.230e-05\n",
            "iter 67: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49635,  0.20587,  0.09481, -0.49843], loss: 7.727e-05\n",
            "iter 68: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49676,  0.20542,  0.09524, -0.49852], loss: 6.474e-05\n",
            "iter 69: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49713,  0.20500,  0.09563, -0.49859], loss: 5.431e-05\n",
            "iter 70: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49746,  0.20460,  0.09598, -0.49866], loss: 4.561e-05\n",
            "iter 71: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49775,  0.20424,  0.09630, -0.49873], loss: 3.834e-05\n",
            "iter 72: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49802,  0.20391,  0.09660, -0.49879], loss: 3.227e-05\n",
            "iter 73: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49825,  0.20360,  0.09686, -0.49884], loss: 2.720e-05\n",
            "iter 74: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49846,  0.20332,  0.09711, -0.49889], loss: 2.295e-05\n",
            "iter 75: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49865,  0.20305,  0.09733, -0.49894], loss: 1.940e-05\n",
            "iter 76: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49882,  0.20281,  0.09753, -0.49899], loss: 1.641e-05\n",
            "iter 77: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49897,  0.20259,  0.09772, -0.49903], loss: 1.391e-05\n",
            "iter 78: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49911,  0.20239,  0.09789, -0.49907], loss: 1.181e-05\n",
            "iter 79: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49923,  0.20220,  0.09805, -0.49911], loss: 1.005e-05\n",
            "iter 80: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49933,  0.20203,  0.09819, -0.49914], loss: 8.561e-06\n",
            "iter 81: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49943,  0.20187,  0.09832, -0.49918], loss: 7.308e-06\n",
            "iter 82: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49952,  0.20172,  0.09844, -0.49921], loss: 6.251e-06\n",
            "iter 83: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49959,  0.20159,  0.09855, -0.49924], loss: 5.359e-06\n",
            "iter 84: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49966,  0.20146,  0.09865, -0.49927], loss: 4.604e-06\n",
            "iter 85: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49972,  0.20135,  0.09875, -0.49930], loss: 3.964e-06\n",
            "iter 86: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49978,  0.20125,  0.09883, -0.49933], loss: 3.421e-06\n",
            "iter 87: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49982,  0.20115,  0.09891, -0.49935], loss: 2.959e-06\n",
            "iter 88: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49987,  0.20107,  0.09899, -0.49938], loss: 2.566e-06\n",
            "iter 89: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49990,  0.20098,  0.09905, -0.49940], loss: 2.231e-06\n",
            "iter 90: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49994,  0.20091,  0.09912, -0.49942], loss: 1.945e-06\n",
            "iter 91: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49997,  0.20084,  0.09917, -0.49945], loss: 1.699e-06\n",
            "iter 92: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.49999,  0.20078,  0.09923, -0.49947], loss: 1.488e-06\n",
            "iter 93: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.50001,  0.20072,  0.09928, -0.49949], loss: 1.307e-06\n",
            "iter 94: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.50003,  0.20067,  0.09932, -0.49951], loss: 1.151e-06\n",
            "iter 95: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.50005,  0.20062,  0.09937, -0.49953], loss: 1.016e-06\n",
            "iter 96: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.50006,  0.20058,  0.09940, -0.49955], loss: 8.988e-07\n",
            "iter 97: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.50008,  0.20054,  0.09944, -0.49956], loss: 7.971e-07\n",
            "iter 98: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.50009,  0.20050,  0.09947, -0.49958], loss: 7.087e-07\n",
            "iter 99: (50,)\n",
            "(50,)\n",
            "(50,)\n",
            "(50,)\n",
            "y_pred = [-0.50010,  0.20046,  0.09951, -0.49960], loss: 6.314e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SvxQOpFMsa7D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}